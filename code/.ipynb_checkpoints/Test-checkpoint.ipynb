{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import sklearn\n",
    "datasets=['statlog','pendigits','musk','letter','covertype','miniboone','cardio','yahoo']#,'scene15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test loading data and a tree classifier\n",
    "X_train=np.loadtxt(\"../data/statlog/sat.trn\")\n",
    "Y_train= X_train[:,-1]\n",
    "X_train=X_train[:,:-1]\n",
    "X_test=np.loadtxt(\"../data/statlog/sat.tst\")\n",
    "Y_test= X_test[:,-1]\n",
    "X_test=X_test[:,:-1]\n",
    "clf = tree.DecisionTreeClassifier(criterion='miser', splitter='best' )\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_pred=clf.predict(X_test)\n",
    "print(np.sum(Y_pred==Y_test)/len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data(data):\n",
    "    if data == 'statlog':\n",
    "        X_train=np.loadtxt(\"../data/statlog/sat.trn\")\n",
    "        Y_train= X_train[:,-1]\n",
    "        X_train=X_train[:,:-1]\n",
    "        X_test=np.loadtxt(\"../data/statlog/sat.tst\")\n",
    "        Y_test= X_test[:,-1]\n",
    "        X_test=X_test[:,:-1]\n",
    "        \n",
    "        return X_train,Y_train,X_test,Y_test\n",
    "    \n",
    "    elif data == 'pendigits':\n",
    "        X_train=np.loadtxt(\"../data/pendigits/pendigits.tra\",delimiter=',')\n",
    "        Y_train= X_train[:,-1]\n",
    "        X_train=X_train[:,:-1]\n",
    "        X_test=np.loadtxt(\"../data/pendigits/pendigits.tes\",delimiter=',')\n",
    "        Y_test= X_test[:,-1]\n",
    "        X_test=X_test[:,:-1]\n",
    "        \n",
    "        return X_train,Y_train,X_test,Y_test\n",
    "    \n",
    "    elif data == 'musk':\n",
    "        X=pd.read_csv(\"../data/musk/clean2.data\",delimiter=',',header=None)\n",
    "        X=X.iloc[:,2:].values\n",
    "        Y= X[:,-1]\n",
    "        X=X[:,:-1]\n",
    "        X_train, X_test, Y_train, Y_test =train_test_split(X,Y, test_size=0.33, random_state=105)\n",
    "        return  X_train,Y_train,X_test,Y_test\n",
    "    \n",
    "    elif data == 'letter':\n",
    "        X=pd.read_csv(\"../data/letter/letter-recognition.data\",delimiter=',',header=None)\n",
    "        X=X.iloc[:,:].values\n",
    "        Y= X[:,0]\n",
    "        Y=np.asarray([ord(y) for y in Y])\n",
    "        X=X[:,1:]\n",
    "        X_train, X_test, Y_train, Y_test =train_test_split(X,Y, test_size=0.33, random_state=105)\n",
    "        return  X_train,Y_train,X_test,Y_test       \n",
    "\n",
    "    elif data == 'covertype':\n",
    "        X=pd.read_csv(\"../data/covertype/covtype.data\",delimiter=',',header=None)\n",
    "        X=X.iloc[:,:].values\n",
    "        Y= X[:,-1]\n",
    "        X=X[:,:-1]\n",
    "        X_train, X_test, Y_train, Y_test =train_test_split(X,Y, test_size=0.33, random_state=105)\n",
    "        return  X_train,Y_train,X_test,Y_test   \n",
    "    elif data == 'miniboone':\n",
    "        X=pd.read_csv(\"../data/miniboone/MiniBooNE.csv\")\n",
    "        X=X.iloc[:,:].values\n",
    "        Y= X[:,0]\n",
    "        Y=Y.astype(\"float\")\n",
    "        X=X[:,1:]\n",
    "        X_train, X_test, Y_train, Y_test =train_test_split(X,Y, test_size=0.33, random_state=105)\n",
    "        \n",
    "        return  X_train,Y_train,X_test,Y_test   \n",
    "    elif data == 'cardio':\n",
    "        X=pd.read_csv(\"../data/cardio/CTG.csv\",header=None,delimiter=';')\n",
    "        X=X.iloc[:,:].values\n",
    "        Y= X[:,-2]\n",
    "        Y=Y.astype(\"float\")\n",
    "        X=X[:,:-4]\n",
    "        X_train, X_test, Y_train, Y_test =train_test_split(X,Y, test_size=0.33, random_state=105)   \n",
    "        return  X_train,Y_train,X_test,Y_test\n",
    "    \n",
    "    elif data == 'yahoo':\n",
    "        X_train=np.loadtxt(\"../data/yahoo/set1.train.csv\",delimiter=',')\n",
    "        Y_train= X_train[:,0]\n",
    "        X_train =X_train[:,1:]\n",
    "        X_test=np.loadtxt(\"../data/yahoo/set1.test.csv\",delimiter=',')\n",
    "        Y_test= X_test[:,0]\n",
    "        X_test=X_test[:,1:]\n",
    "        \n",
    "        return X_train,Y_train,X_test,Y_test \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test get data \n",
    "\n",
    "# X_train,Y_train,X_test,Y_test=get_data('yahoo')\n",
    "# clf = tree.DecisionTreeClassifier(criterion='miser', splitter='best' )\n",
    "# clf = clf.fit(X_train, Y_train)\n",
    "# Y_pred=clf.predict(X_test)\n",
    "# print(np.sum(Y_pred==Y_test)/len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statlog: 3.0\n",
      "pendigits: 8.0\n",
      "musk: 1.0\n",
      "letter: 81\n",
      "covertype: 1\n",
      "miniboone: 1.0\n",
      "cardio: 6.0\n",
      "yahoo: 0.0\n"
     ]
    }
   ],
   "source": [
    "# convert data to svm light\n",
    "\n",
    "# from sklearn.datasets import dump_svmlight_file\n",
    "# import os\n",
    "\n",
    "# for data in datasets:\n",
    "#     X_train,Y_train,X_test,Y_test =get_data(data)\n",
    "# #     os.mkdir('../data/'+data+'/svm/')\n",
    "#     dump_svmlight_file(X_train, Y_train, '../data/'+data+'/svm/train.txt', zero_based=False, comment=None, query_id=[0]*len(Y_train), multilabel=False)\n",
    "#     dump_svmlight_file(X_test, Y_test, '../data/'+data+'/svm/test.txt', zero_based=False, comment=None, query_id=[0]*len(Y_test), multilabel=False)\n",
    "#     print(data+\": \"+str(Y_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from greedymiser.miser import miser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature unused:29\n",
      "feature unused:26\n",
      "feature unused:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0,  4.27069,    4.31631\n",
      "1,  3.87290,    3.91904\n",
      "2,  3.51719,    3.56088\n",
      "3,  3.19953,    3.24227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature unused:19\n",
      "feature unused:17\n",
      "feature unused:16\n",
      "feature unused:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4,  2.91536,    2.95778\n",
      "5,  2.66259,    2.70548\n",
      "6,  2.43459,    2.48035\n",
      "7,  2.23142,    2.27751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature unused:13\n",
      "feature unused:12\n",
      "feature unused:10\n",
      "feature unused:9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8,  2.05118,    2.10045\n",
      "9,  1.88806,    1.94128\n",
      "10,  1.74809,    1.80477\n",
      "11,  1.62122,    1.68295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature unused:9\n",
      "feature unused:7\n",
      "feature unused:6\n",
      "feature unused:6\n",
      "feature unused:6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12,  1.50984,    1.57562\n",
      "13,  1.41210,    1.48188\n",
      "14,  1.32663,    1.40105\n",
      "15,  1.25200,    1.32986\n"
     ]
    }
   ],
   "source": [
    "x=miser()\n",
    "x.fit(path='statlog',costs= \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.COSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "budget",
   "language": "python",
   "name": "budget"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
