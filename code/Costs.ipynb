{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=True, random_state=0, verbose=0, warm_start=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict\n",
    "from sklearn.datasets import make_classification \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RANDOM_STATE=0\n",
    "\n",
    "X, y = make_classification(n_samples=1500, n_features=25,\n",
    "                           n_clusters_per_class=1, n_informative=15,\n",
    "                           random_state=RANDOM_STATE)\n",
    "clf=RandomForestClassifier(n_estimators=100,\n",
    "                       warm_start=True, oob_score=True,\n",
    "                       max_features=\"sqrt\",\n",
    "                       random_state=RANDOM_STATE)\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([118,  53,  38,   9,   8,   7,  -1,  -1,  -1,  29,  20,  19,  18,\n",
       "        17,  16,  -1,  -1,  -1,  -1,  -1,  28,  27,  24,  -1,  26,  -1,\n",
       "        -1,  -1,  -1,  37,  34,  33,  -1,  -1,  36,  -1,  -1,  -1,  52,\n",
       "        41,  -1,  43,  -1,  51,  48,  47,  -1,  -1,  50,  -1,  -1,  -1,\n",
       "        -1,  95,  60,  57,  -1,  59,  -1,  -1,  84,  75,  66,  65,  -1,\n",
       "        -1,  74,  69,  -1,  73,  72,  -1,  -1,  -1,  -1,  79,  78,  -1,\n",
       "        -1,  81,  -1,  83,  -1,  -1,  86,  -1,  94,  93,  90,  -1,  92,\n",
       "        -1,  -1,  -1,  -1, 107, 106, 105, 104, 103, 102,  -1,  -1,  -1,\n",
       "        -1,  -1,  -1, 109,  -1, 111,  -1, 113,  -1, 115,  -1, 117,  -1,\n",
       "        -1, 196, 181, 166, 141, 134, 131, 130, 129, 128,  -1,  -1,  -1,\n",
       "        -1, 133,  -1,  -1, 136,  -1, 138,  -1, 140,  -1,  -1, 159, 158,\n",
       "       147, 146,  -1,  -1, 151, 150,  -1,  -1, 157, 154,  -1, 156,  -1,\n",
       "        -1,  -1,  -1, 165, 164, 163,  -1,  -1,  -1,  -1, 168,  -1, 172,\n",
       "       171,  -1,  -1, 180, 177, 176,  -1,  -1, 179,  -1,  -1,  -1, 189,\n",
       "       184,  -1, 186,  -1, 188,  -1,  -1, 193, 192,  -1,  -1, 195,  -1,\n",
       "        -1, 222, 213, 212, 205, 204, 203,  -1,  -1,  -1, 209, 208,  -1,\n",
       "        -1, 211,  -1,  -1,  -1, 219, 218, 217,  -1,  -1,  -1, 221,  -1,\n",
       "        -1, 246, 237, 232, 227,  -1, 231, 230,  -1,  -1,  -1, 236, 235,\n",
       "        -1,  -1,  -1, 239,  -1, 241,  -1, 245, 244,  -1,  -1,  -1,  -1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.estimators_[0].tree_.children_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Tree in module sklearn.tree._tree:\n",
      "\n",
      "class Tree(builtins.object)\n",
      " |  Array-based representation of a binary decision tree.\n",
      " |  \n",
      " |  The binary tree is represented as a number of parallel arrays. The i-th\n",
      " |  element of each array holds information about the node `i`. Node 0 is the\n",
      " |  tree's root. You can find a detailed description of all arrays in\n",
      " |  `_tree.pxd`. NOTE: Some of the arrays only apply to either leaves or split\n",
      " |  nodes, resp. In this case the values of nodes of the other type are\n",
      " |  arbitrary!\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  node_count : int\n",
      " |      The number of nodes (internal nodes + leaves) in the tree.\n",
      " |  \n",
      " |  capacity : int\n",
      " |      The current capacity (i.e., size) of the arrays, which is at least as\n",
      " |      great as `node_count`.\n",
      " |  \n",
      " |  max_depth : int\n",
      " |      The maximal depth of the tree.\n",
      " |  \n",
      " |  children_left : array of int, shape [node_count]\n",
      " |      children_left[i] holds the node id of the left child of node i.\n",
      " |      For leaves, children_left[i] == TREE_LEAF. Otherwise,\n",
      " |      children_left[i] > i. This child handles the case where\n",
      " |      X[:, feature[i]] <= threshold[i].\n",
      " |  \n",
      " |  children_right : array of int, shape [node_count]\n",
      " |      children_right[i] holds the node id of the right child of node i.\n",
      " |      For leaves, children_right[i] == TREE_LEAF. Otherwise,\n",
      " |      children_right[i] > i. This child handles the case where\n",
      " |      X[:, feature[i]] > threshold[i].\n",
      " |  \n",
      " |  feature : array of int, shape [node_count]\n",
      " |      feature[i] holds the feature to split on, for the internal node i.\n",
      " |  \n",
      " |  threshold : array of double, shape [node_count]\n",
      " |      threshold[i] holds the threshold for the internal node i.\n",
      " |  \n",
      " |  value : array of double, shape [node_count, n_outputs, max_n_classes]\n",
      " |      Contains the constant prediction value of each node.\n",
      " |  \n",
      " |  impurity : array of double, shape [node_count]\n",
      " |      impurity[i] holds the impurity (i.e., the value of the splitting\n",
      " |      criterion) at node i.\n",
      " |  \n",
      " |  n_node_samples : array of int, shape [node_count]\n",
      " |      n_node_samples[i] holds the number of training samples reaching node i.\n",
      " |  \n",
      " |  weighted_n_node_samples : array of int, shape [node_count]\n",
      " |      weighted_n_node_samples[i] holds the weighted number of training samples\n",
      " |      reaching node i.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getstate__(...)\n",
      " |      Getstate re-implementation, for pickling.\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  __reduce__(...)\n",
      " |      Reduce re-implementation, for pickling.\n",
      " |  \n",
      " |  __setstate__(...)\n",
      " |      Setstate re-implementation, for unpickling.\n",
      " |  \n",
      " |  apply(...)\n",
      " |      Finds the terminal region (=leaf node) for each sample in X.\n",
      " |  \n",
      " |  compute_feature_importances(...)\n",
      " |      Computes the importance of each feature (aka variable).\n",
      " |  \n",
      " |  decision_path(...)\n",
      " |      Finds the decision path (=node) for each sample in X.\n",
      " |  \n",
      " |  predict(...)\n",
      " |      Predict target for X.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  capacity\n",
      " |  \n",
      " |  children_left\n",
      " |  \n",
      " |  children_right\n",
      " |  \n",
      " |  feature\n",
      " |  \n",
      " |  impurity\n",
      " |  \n",
      " |  max_depth\n",
      " |  \n",
      " |  max_n_classes\n",
      " |  \n",
      " |  n_classes\n",
      " |  \n",
      " |  n_features\n",
      " |  \n",
      " |  n_node_samples\n",
      " |  \n",
      " |  n_outputs\n",
      " |  \n",
      " |  node_count\n",
      " |  \n",
      " |  threshold\n",
      " |  \n",
      " |  value\n",
      " |  \n",
      " |  weighted_n_node_samples\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __pyx_vtable__ = <capsule object NULL>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "help(sklearn.tree._tree.Tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_extraction_cost(estimator,costs):\n",
    "    features_used= set(estimator.tree_.feature)\n",
    "    cost=0\n",
    "    for f in features_used:\n",
    "        cost+=costs[f]\n",
    "    return cost\n",
    "\n",
    "def rf_extraction_cost(rf,costs):\n",
    "    features_used= set()\n",
    "    for estimator in rf.estimators_:\n",
    "        features_used=features_used.union(set(estimator.tree_.feature))\n",
    "    features_used.remove(-2)\n",
    "    cost=0\n",
    "    for f in features_used:\n",
    "        cost+=costs[f]\n",
    "    return cost\n",
    "\n",
    "def tree_evaluation_cost(estimator,node=0,depth=1):\n",
    "    if estimator.tree_.children_left[node]==-1 :\n",
    "        return estimator.tree_.weighted_n_node_samples[node]*depth\n",
    "    return tree_evaluation_cost(estimator,estimator.tree_.children_left[node],depth+1)+\\\n",
    "           tree_evaluation_cost(estimator,estimator.tree_.children_right[node],depth+1)\n",
    "    \n",
    "def forest_evaluation_cost(rf):\n",
    "    cost=0\n",
    "    for estimator in rf.estimators_:\n",
    "        cost+=tree_evaluation_cost(estimator)\n",
    "tree_evaluation_cost(clf.estimators_[0])\n",
    "\n",
    "def tree_budget_exact(estimator):\n",
    "    tree_evaluation_cost(estimator)+tree_extraction_cost(estimator)\n",
    "    \n",
    "def forest_budget_exact(rf):\n",
    "    forest_evaluation_cost(rf)+forest_extraction_cost(rf)\n",
    "    \n",
    "def tree_budget_rough(estimator,tree_cost=1):\n",
    "    tree_cost+tree_extraction_cost(estimator)\n",
    "    \n",
    "def forest_budget_rough(rf,tree_cost=1):\n",
    "    tree_cost*rf.n_estimators+forest_extraction_cost(rf)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "budget",
   "language": "python",
   "name": "budget"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
